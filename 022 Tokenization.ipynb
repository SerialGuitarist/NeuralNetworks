{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9f6ec2",
   "metadata": {},
   "source": [
    "Feature extraction can rarely retain all the information content of the input data in any machine learning pipeline. In NLP you have to find the balance of where your tokenizer needs to be adjusted to extract different or more information for the particular applciation\n",
    "\n",
    "# Stemming\n",
    "How do you cut a word into its semantically significant bits?\n",
    "\n",
    "You want to remove the \"ing\" from verbs, so \"ending\" becomes \"end\", and \"running\" to \"run\", but \"sing\" should remain intact. Letters can be very misleading\n",
    "\n",
    "Approaches include the likes of statistically finding the \"semantic stems\" from a large collection of natural language text\n",
    "\n",
    "# Tokenization\n",
    "A particular kind of document segmentation. Segmentation is breaking up text into smaller chunks or segments, with more focused information. Tokenization segments the document into Tokens\n",
    "\n",
    "A tokenizer can also be found in a compiler, aka a scanner or lexer, reading code and matching it against the *lexicon*, or the set of all the valid tokes, ie the vocabulary. A *scannerless parser* is a compiler with a tokenizer incorporated into the parser.\n",
    "\n",
    "As the first step in an NLP pipeline, has big impact on the rest\n",
    "\n",
    "Basic approach: using the python `split` to create one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b9f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Along', 'cloud,', 'down', 'drifting', 'eagle', 'land.', 'on', 'searching', 'the']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence = \"Along the drifting cloud, the eagle searching down on the land.\"\n",
    "token_sequence = sentence.split()\n",
    "vocab = sorted(set(token_sequence))\n",
    "print(vocab)\n",
    "\n",
    "num_tokens = len(token_sequence)\n",
    "vocab_size = len(vocab)\n",
    "onehot_vectors = np.zeros((num_tokens,\n",
    "                           vocab_size), int)\n",
    "for i, word in enumerate(token_sequence):\n",
    "    onehot_vectors[i, vocab.index(word)] = 1\n",
    "onehot_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd14e11",
   "metadata": {},
   "source": [
    "Pandas DataFrames can make it a little easier to interpret (think of R's dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "924dc039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Along</th>\n",
       "      <th>cloud,</th>\n",
       "      <th>down</th>\n",
       "      <th>drifting</th>\n",
       "      <th>eagle</th>\n",
       "      <th>land.</th>\n",
       "      <th>on</th>\n",
       "      <th>searching</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Along  cloud,  down  drifting  eagle  land.  on  searching  the\n",
       "0       1       0     0         0      0      0   0          0    0\n",
       "1       0       0     0         0      0      0   0          0    1\n",
       "2       0       0     0         1      0      0   0          0    0\n",
       "3       0       1     0         0      0      0   0          0    0\n",
       "4       0       0     0         0      0      0   0          0    1\n",
       "5       0       0     0         0      1      0   0          0    0\n",
       "6       0       0     0         0      0      0   0          1    0\n",
       "7       0       0     1         0      0      0   0          0    0\n",
       "8       0       0     0         0      0      0   1          0    0\n",
       "9       0       0     0         0      0      0   0          0    1\n",
       "10      0       0     0         0      0      1   0          0    0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(onehot_vectors, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9de5a",
   "metadata": {},
   "source": [
    "A super sparse data structure, but no information is lost, so useful for neural nets: seq2seq models, and generative language models.\n",
    "\n",
    "Immensely increases the size of the data though. A dataset with a million tokens, containing 3000 books with 3500 sentences each, with 15 words per sentence totals to 157.5 terabyes. Fortunately all this data will cycle through the RAM, and never be stored.\n",
    "\n",
    "But preferably we want to compress a document down to a single vector rather than big table, which is possible if we're willing to give up the ability recall perfectly. By summing up all the one hot vectors, we get a bag of words, which contain information from which the meaning of the document can be roughly inferred. And if you limit the tokens to the 10k most important ones, the afforementioned 3k books go down to 30 MB\n",
    "\n",
    "A balance between the one hot vector and bag of words could be bag of words for each sentence, Another approach is a binary array, keeping track of the presense or absence of a word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c7b6fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Along', 1),\n",
       " ('cloud,', 1),\n",
       " ('down', 1),\n",
       " ('drifting', 1),\n",
       " ('eagle', 1),\n",
       " ('land.', 1),\n",
       " ('on', 1),\n",
       " ('searching', 1),\n",
       " ('the', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bow = {}\n",
    "for token in sentence.split():\n",
    "    sentence_bow[token] = 1\n",
    "sorted(sentence_bow.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bbcb5",
   "metadata": {},
   "source": [
    "The use of a dictionary or a hashtable here ensures the data is only as big as it needs to be. The dictionary can be made even more efficient by storing an integer pointer to the word instead of the word itself\n",
    "\n",
    "A Pandas `Series` is an even more efficient dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43e8702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Along</th>\n",
       "      <th>the</th>\n",
       "      <th>drifting</th>\n",
       "      <th>cloud,</th>\n",
       "      <th>eagle</th>\n",
       "      <th>searching</th>\n",
       "      <th>down</th>\n",
       "      <th>on</th>\n",
       "      <th>land.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Along  the  drifting  cloud,  eagle  searching  down  on  land.\n",
       "sent      1    1         1       1      1          1     1   1      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pd.Series(dict([(token, 1) for token in sentence.split()])), columns=['sent']).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58db3728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catching</th>\n",
       "      <th>the</th>\n",
       "      <th>swirling</th>\n",
       "      <th>wind,</th>\n",
       "      <th>sailor</th>\n",
       "      <th>sees</th>\n",
       "      <th>rim</th>\n",
       "      <th>of</th>\n",
       "      <th>land.</th>\n",
       "      <th>The</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Catching  the  swirling  wind,  sailor  sees  rim  of  land.  The\n",
       "sent0         1    1         1      1       1     1    1   1      1    0\n",
       "sent1         0    0         0      0       0     0    0   1      0    1\n",
       "sent2         0    1         0      0       0     0    0   1      0    0\n",
       "sent3         0    0         0      0       0     0    0   0      0    0\n",
       "sent4         0    0         0      0       0     0    0   0      0    0\n",
       "sent5         0    1         0      0       0     0    0   0      0    0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Catching the swirling wind, the sailor sees the rim of the land.\",\n",
    "    \"The eagle's dancing wings create as weather spins out of hand.\",\n",
    "    \"Go closer hold the land feel partly no more than grains of sand.\",\n",
    "    \"We stand to lose all time a thousand answers by in our hand.\",\n",
    "    \"Next to your deeper fears we stand surrounded by million years.\",\n",
    "    \"I'll be the roundabout.\"\n",
    "]\n",
    "\n",
    "corpus = {}\n",
    "for i, sent in enumerate(sentences):\n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in sent.split())\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "df[df.columns[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6462b0",
   "metadata": {},
   "source": [
    "Clearly very little overlap exists between the sentences. Computing overlap can be done through a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb5041d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catching       0\n",
       "the            1\n",
       "swirling       0\n",
       "wind,          0\n",
       "sailor         0\n",
       "sees           0\n",
       "rim            0\n",
       "of             1\n",
       "land.          0\n",
       "The            0\n",
       "eagle's        0\n",
       "dancing        0\n",
       "wings          0\n",
       "create         0\n",
       "as             0\n",
       "weather        0\n",
       "spins          0\n",
       "out            0\n",
       "hand.          0\n",
       "Go             1\n",
       "closer         1\n",
       "hold           1\n",
       "land           1\n",
       "feel           1\n",
       "partly         1\n",
       "no             1\n",
       "more           1\n",
       "than           1\n",
       "grains         1\n",
       "sand.          1\n",
       "We             0\n",
       "stand          0\n",
       "to             0\n",
       "lose           0\n",
       "all            0\n",
       "time           0\n",
       "a              0\n",
       "thousand       0\n",
       "answers        0\n",
       "by             0\n",
       "in             0\n",
       "our            0\n",
       "Next           0\n",
       "your           0\n",
       "deeper         0\n",
       "fears          0\n",
       "we             0\n",
       "surrounded     0\n",
       "million        0\n",
       "years.         0\n",
       "I'll           0\n",
       "be             0\n",
       "roundabout.    0\n",
       "Name: sent2, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df.sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8e53a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4e296",
   "metadata": {},
   "source": [
    "There is one word shared between the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425e5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
