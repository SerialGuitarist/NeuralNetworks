{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b2e4e2",
   "metadata": {},
   "source": [
    "The whole point of making and training this model has been to predict values, so here it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74621c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Model class\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create a list of network objects\n",
    "        self.layers = []\n",
    "        # Softmax classifier's output object\n",
    "        self.softmax_classifier_output = None\n",
    "\n",
    "    # Add objects to the model\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "\n",
    "    # Set loss, optimizer and accuracy\n",
    "    def set(self, *, loss = None, optimizer = None, accuracy = None):\n",
    "        if loss is not None:\n",
    "            self.loss = loss\n",
    "        if optimizer is not None:\n",
    "            self.optimizer = optimizer\n",
    "        if accuracy is not None:\n",
    "            self.accuracy = accuracy\n",
    "\n",
    "    # Finalize the model\n",
    "    def finalize(self):\n",
    "\n",
    "        # Create and set the input layer\n",
    "        self.input_layer = Layer_Input()\n",
    "\n",
    "        # Count all the objects\n",
    "        layer_count = len(self.layers)\n",
    "\n",
    "        # Initialize a list containing trainable layers:\n",
    "        self.trainable_layers = []\n",
    "\n",
    "        # Iterate the objects\n",
    "        for i in range(layer_count):\n",
    "\n",
    "            # If it's the first layer,\n",
    "            # the previous layer object is the input layer\n",
    "            if i == 0:\n",
    "                self.layers[i].prev = self.input_layer\n",
    "                self.layers[i].next = self.layers[i+1]\n",
    "\n",
    "            # All layers except for the first and the last\n",
    "            elif i < layer_count - 1:\n",
    "                self.layers[i].prev = self.layers[i-1]\n",
    "                self.layers[i].next = self.layers[i+1]\n",
    "\n",
    "            # The last layer - the next object is the loss\n",
    "            # Also let's save aside the reference to the last object\n",
    "            # whose output is the model's output\n",
    "            else:\n",
    "                self.layers[i].prev = self.layers[i-1]\n",
    "                self.layers[i].next = self.loss\n",
    "                self.output_layer_activation = self.layers[i]\n",
    "\n",
    "            # If layer contains an attribute called \"weights\",\n",
    "            # it's a trainable layer -\n",
    "            # add it to the list of trainable layers\n",
    "            # We don't need to check for biases -\n",
    "            # checking for weights is enough\n",
    "            if hasattr(self.layers[i], 'weights'):\n",
    "                self.trainable_layers.append(self.layers[i])\n",
    "\n",
    "\n",
    "        # Update loss object with trainable layers\n",
    "        if self.loss is not None:\n",
    "            self.loss.remember_trainable_layers(\n",
    "                self.trainable_layers\n",
    "            )\n",
    "\n",
    "        # If output activation is Softmax and\n",
    "        # loss function is Categorical Cross-Entropy\n",
    "        # create an object of combined activation\n",
    "        # and loss function containing\n",
    "        # faster gradient calculation\n",
    "        if isinstance(self.layers[-1], Activation_Softmax) and \\\n",
    "           isinstance(self.loss, Loss_CategoricalCrossentropy):\n",
    "            # Create an object of combined activation\n",
    "            # and loss functions\n",
    "            self.softmax_classifier_output = \\\n",
    "                Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Train the model\n",
    "    def train(self, X, y, *, epochs=1, batch_size=None,\n",
    "              print_every=1, validation_data=None):\n",
    "\n",
    "        # Initialize accuracy object\n",
    "        self.accuracy.init(y)\n",
    "\n",
    "        # Default value if batch size is not being set\n",
    "        train_steps = 1\n",
    "\n",
    "        # If there is validation data passed,\n",
    "        # set default number of steps for validation as well\n",
    "        if validation_data is not None:\n",
    "            validation_steps = 1\n",
    "\n",
    "            # For better readability\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        # Calculate number of steps\n",
    "        if batch_size is not None:\n",
    "            train_steps = len(X) // batch_size\n",
    "            # Dividing rounds down. If there are some remaining\n",
    "            # data but not a full batch, this won't include it\n",
    "            # Add `1` to include this not full batch\n",
    "            if train_steps * batch_size < len(X):\n",
    "                train_steps += 1\n",
    "\n",
    "            if validation_data is not None:\n",
    "                validation_steps = len(X_val) // batch_size\n",
    "\n",
    "                # Dividing rounds down. If there are some remaining\n",
    "                # data but nor full batch, this won't include it\n",
    "                # Add `1` to include this not full batch\n",
    "                if validation_steps * batch_size < len(X_val):\n",
    "                    validation_steps += 1\n",
    "\n",
    "        # Main training loop\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            # Print epoch number\n",
    "            print(f'epoch: {epoch}')\n",
    "\n",
    "            # Reset accumulated values in loss and accuracy objects\n",
    "            self.loss.new_pass()\n",
    "            self.accuracy.new_pass()\n",
    "\n",
    "            # Iterate over steps\n",
    "            for step in range(train_steps):\n",
    "\n",
    "                # If batch size is not set -\n",
    "                # train using one step and full dataset\n",
    "                if batch_size is None:\n",
    "                    batch_X = X\n",
    "                    batch_y = y\n",
    "\n",
    "                # Otherwise slice a batch\n",
    "                else:\n",
    "                    batch_X = X[step*batch_size:(step+1)*batch_size]\n",
    "                    batch_y = y[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "                # Perform the forward pass\n",
    "                output = self.forward(batch_X, training=True)\n",
    "\n",
    "                # Calculate loss\n",
    "                data_loss, regularization_loss = \\\n",
    "                    self.loss.calculate(output, batch_y,\n",
    "                                        include_regularization=True)\n",
    "                loss = data_loss + regularization_loss\n",
    "\n",
    "                # Get predictions and calculate an accuracy\n",
    "                predictions = self.output_layer_activation.predictions(\n",
    "                                  output)\n",
    "                accuracy = self.accuracy.calculate(predictions,\n",
    "                                                   batch_y)\n",
    "\n",
    "                # Perform backward pass\n",
    "                self.backward(output, batch_y)\n",
    "\n",
    "\n",
    "                # Optimize (update parameters)\n",
    "                self.optimizer.pre_update_params()\n",
    "                for layer in self.trainable_layers:\n",
    "                    self.optimizer.update_params(layer)\n",
    "                self.optimizer.post_update_params()\n",
    "\n",
    "                # Print a summary\n",
    "                if not step % print_every or step == train_steps - 1:\n",
    "                    print(f'step: {step}, ' +\n",
    "                          f'acc: {accuracy:.3f}, ' +\n",
    "                          f'loss: {loss:.3f} (' +\n",
    "                          f'data_loss: {data_loss:.3f}, ' +\n",
    "                          f'reg_loss: {regularization_loss:.3f}), ' +\n",
    "                          f'lr: {self.optimizer.current_learning_rate}')\n",
    "\n",
    "            # Get and print epoch loss and accuracy\n",
    "            epoch_data_loss, epoch_regularization_loss = \\\n",
    "                self.loss.calculate_accumulated(\n",
    "                    include_regularization=True)\n",
    "            epoch_loss = epoch_data_loss + epoch_regularization_loss\n",
    "            epoch_accuracy = self.accuracy.calculate_accumulated()\n",
    "\n",
    "            print(f'training, ' +\n",
    "                  f'acc: {epoch_accuracy:.3f}, ' +\n",
    "                  f'loss: {epoch_loss:.3f} (' +\n",
    "                  f'data_loss: {epoch_data_loss:.3f}, ' +\n",
    "                  f'reg_loss: {epoch_regularization_loss:.3f}), ' +\n",
    "                  f'lr: {self.optimizer.current_learning_rate}')\n",
    "\n",
    "            # If there is the validation data\n",
    "            if validation_data is not None:\n",
    "\n",
    "                # evaluate the model\n",
    "                self.evaluate(*validation_data,\n",
    "                              batch_size = batch_size)\n",
    "                # * explodes the data into individual arguments\n",
    "\n",
    "    # Performs forward pass\n",
    "    def forward(self, X, training):\n",
    "\n",
    "        # Call forward method on the input layer\n",
    "        # this will set the output property that\n",
    "        # the first layer in \"prev\" object is expecting\n",
    "        self.input_layer.forward(X, training)\n",
    "\n",
    "        # Call forward method of every object in a chain\n",
    "        # Pass output of the previous object as a parameter\n",
    "        for layer in self.layers:\n",
    "            layer.forward(layer.prev.output, training)\n",
    "\n",
    "        # \"layer\" is now the last object from the list,\n",
    "        # return its output\n",
    "        return layer.output\n",
    "\n",
    "\n",
    "    # Performs backward pass\n",
    "    def backward(self, output, y):\n",
    "\n",
    "        # If softmax classifier\n",
    "        if self.softmax_classifier_output is not None:\n",
    "            # First call backward method\n",
    "            # on the combined activation/loss\n",
    "            # this will set dinputs property\n",
    "            self.softmax_classifier_output.backward(output, y)\n",
    "\n",
    "            # Since we'll not call backward method of the last layer\n",
    "            # which is Softmax activation\n",
    "            # as we used combined activation/loss\n",
    "            # object, let's set dinputs in this object\n",
    "            self.layers[-1].dinputs = \\\n",
    "                self.softmax_classifier_output.dinputs\n",
    "\n",
    "            # Call backward method going through\n",
    "            # all the objects but last\n",
    "            # in reversed order passing dinputs as a parameter\n",
    "            for layer in reversed(self.layers[:-1]):\n",
    "                layer.backward(layer.next.dinputs)\n",
    "\n",
    "            return\n",
    "\n",
    "        # First call backward method on the loss\n",
    "        # this will set dinputs property that the last\n",
    "        # layer will try to access shortly\n",
    "        self.loss.backward(output, y)\n",
    "\n",
    "        # Call backward method going through all the objects\n",
    "        # in reversed order passing dinputs as a parameter\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward(layer.next.dinputs)\n",
    "    \n",
    "    # evaluates the model using passed in dataset\n",
    "    def evaluate(self, X_val, y_val, *, batch_size = None):\n",
    "        \n",
    "        # default value if batch size is not being set\n",
    "        validation_steps = 1\n",
    "        \n",
    "        # calculate number of steps\n",
    "        if batch_size is not None:\n",
    "            validation_steps = len(X_val) // batch_size\n",
    "            # another batch from remainders\n",
    "            if validation_steps * batch_size < len(X_val):\n",
    "                validation_steps += 1\n",
    "\n",
    "        # Reset accumulated values in loss\n",
    "        # and accuracy objects\n",
    "        self.loss.new_pass()\n",
    "        self.accuracy.new_pass()\n",
    "\n",
    "        # Iterate over steps\n",
    "        for step in range(validation_steps):\n",
    "\n",
    "            # If batch size is not set -\n",
    "            # train using one step and full dataset\n",
    "            if batch_size is None:\n",
    "                batch_X = X_val\n",
    "                batch_y = y_val\n",
    "\n",
    "\n",
    "            # Otherwise slice a batch\n",
    "            else:\n",
    "                batch_X = X_val[\n",
    "                    step*batch_size:(step+1)*batch_size\n",
    "                ]\n",
    "                batch_y = y_val[\n",
    "                    step*batch_size:(step+1)*batch_size\n",
    "                ]\n",
    "\n",
    "            # Perform the forward pass\n",
    "            output = self.forward(batch_X, training=False)\n",
    "\n",
    "            # Calculate the loss\n",
    "            self.loss.calculate(output, batch_y)\n",
    "\n",
    "            # Get predictions and calculate an accuracy\n",
    "            predictions = self.output_layer_activation.predictions(\n",
    "                              output)\n",
    "            self.accuracy.calculate(predictions, batch_y)\n",
    "\n",
    "        # Get and print validation loss and accuracy\n",
    "        validation_loss = self.loss.calculate_accumulated()\n",
    "        validation_accuracy = self.accuracy.calculate_accumulated()\n",
    "\n",
    "        # Print a summary\n",
    "        print(f'validation, ' +\n",
    "              f'acc: {validation_accuracy:.3f}, ' +\n",
    "              f'loss: {validation_loss:.3f}')\n",
    "\n",
    "    # Retrieves and returns parameters of trainable layers\n",
    "    def get_parameters(self):\n",
    "        \n",
    "        # create a list for paremeters\n",
    "        parameters = []\n",
    "        \n",
    "        # iterate trainable layers and get their parameters\n",
    "        for layer in self.trainable_layers:\n",
    "            parameters.append(layer.get_parameters())\n",
    "            \n",
    "        # return a list\n",
    "        return parameters\n",
    "    \n",
    "    # Updates the model with new parameters\n",
    "    def set_parameters(self, parameters):\n",
    "        \n",
    "        # iterate over the parameters and layers\n",
    "        # and update each layers with each set of the parameters\n",
    "        for parameter_set, layer in zip(parameters, \n",
    "                                        self.trainable_layers):\n",
    "            layer.set_parameters(*parameter_set)\n",
    "            \n",
    "    # saves the parameters to a file\n",
    "    def save_parameters(self, path):\n",
    "        \n",
    "        # open a file in the binary-write mode\n",
    "        # and save parameters to it\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.get_parameters(), f)\n",
    "            \n",
    "    # loads the weights and updates a model instance with them\n",
    "    def load_paremeters(self, path):\n",
    "        \n",
    "        # open file in the binary-read mode,\n",
    "        # load weights and update trainabe layers\n",
    "        with open(path, 'rb') as f:\n",
    "            self.set_parameters(pickle.load(f))\n",
    "            \n",
    "    def save(self, path):\n",
    "        \n",
    "        # make a deepy copy of the current model instance\n",
    "        model = copy.deepcopy(self)\n",
    "        \n",
    "        # reset accumulated values in loss and accuracy objects\n",
    "        model.loss.new_pass()\n",
    "        mode.accuracy.new_pass()\n",
    "        \n",
    "        # remove data from the input layer\n",
    "        # and gradients from the loss object\n",
    "        model.input_layer.__dict__.pop('output', None)\n",
    "        model.loss.__dict__.pop('dinputs', None)\n",
    "        \n",
    "        # for each layer remove inputs, outputs and gradient properties\n",
    "        for layer in model.layers:\n",
    "            for property in ['inputs', 'output', 'dinputs', \n",
    "                             'dweights', 'dbiases']:\n",
    "                layer.__dict__pop(property, None)\n",
    "                \n",
    "        # open a file in the binary-write mode and save the model\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "            \n",
    "    # loads and returns a model\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        \n",
    "        # open file in the binary-read mode\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            \n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "    def predict(self, X, *, batch_size = None):\n",
    "        \n",
    "        # Default value if batch size is not being set\n",
    "        prediction_steps = 1\n",
    "        \n",
    "        # calculate number of steps\n",
    "        if batch_size is not None:\n",
    "            prediction_steps = len(X) // batch_size\n",
    "            if prediction_steps * batch_size < len(X):\n",
    "                prediction_steps += 1\n",
    "        \n",
    "        # iterate over steps\n",
    "        for step in range(prediction_steps):\n",
    "            \n",
    "            # if batch size is not set\n",
    "            # train using one step and full dataset\n",
    "            if batch_size is None:\n",
    "                batch_X\n",
    "            \n",
    "            # otherwise slice a batch\n",
    "            else:\n",
    "                batch_X = X[step * batch_size: (step + 1) * batch_size]\n",
    "            \n",
    "            # perform the forward pass\n",
    "            batch_output = self.forward(batch_X, training = False)\n",
    "            \n",
    "            # Append batch prediction to the list of predictions\n",
    "            output.append(batch_output)\n",
    "        \n",
    "        # stack and return results\n",
    "        return np.vstack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4d827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "342b6a4b",
   "metadata": {},
   "source": [
    "Making the full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5851eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons,\n",
    "                 weight_regularizer_l1=0, weight_regularizer_l2=0,\n",
    "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        # Set regularization strength\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "        # Gradients on regularization\n",
    "        # L1 on weights\n",
    "        if self.weight_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.weights)\n",
    "            dL1[self.weights < 0] = -1\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1\n",
    "        # L2 on weights\n",
    "        if self.weight_regularizer_l2 > 0:\n",
    "            self.dweights += 2 * self.weight_regularizer_l2 * \\\n",
    "                             self.weights\n",
    "        # L1 on biases\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.biases)\n",
    "            dL1[self.biases < 0] = -1\n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "        # L2 on biases\n",
    "        if self.bias_regularizer_l2 > 0:\n",
    "            self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
    "                            self.biases\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "        \n",
    "    # Retrive layer paremters\n",
    "    def get_parameters(self):\n",
    "        return self.weights, self.biases\n",
    "    \n",
    "    # Set weights and biases in a layer instance\n",
    "    def set_parameters(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "\n",
    "\n",
    "# Dropout\n",
    "class Layer_Dropout:\n",
    "\n",
    "    # Init\n",
    "    def __init__(self, rate):\n",
    "        # Store rate, we invert it as for example for dropout\n",
    "        # of 0.1 we need success rate of 0.9\n",
    "        self.rate = 1 - rate\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        # Save input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # If not in the training mode - return values\n",
    "        if not training:\n",
    "            self.output = inputs.copy()\n",
    "            return\n",
    "\n",
    "        # Generate and save scaled mask\n",
    "        self.binary_mask = np.random.binomial(1, self.rate,\n",
    "                           size=inputs.shape) / self.rate\n",
    "        # Apply mask to output values\n",
    "        self.output = inputs * self.binary_mask\n",
    "\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradient on values\n",
    "        self.dinputs = dvalues * self.binary_mask\n",
    "\n",
    "\n",
    "# Input \"layer\"\n",
    "class Layer_Input:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        self.output = inputs\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "    # Calculate predictions for outputs\n",
    "    def predictions(self, outputs):\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "                enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                              np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n",
    "\n",
    "    # Calculate predictions for outputs\n",
    "    def predictions(self, outputs):\n",
    "        return np.argmax(outputs, axis=1)\n",
    "\n",
    "\n",
    "# Sigmoid activation\n",
    "class Activation_Sigmoid:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        # Save input and calculate/save output\n",
    "        # of the sigmoid function\n",
    "        self.inputs = inputs\n",
    "        self.output = 1 / (1 + np.exp(-inputs))\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Derivative - calculates from output of the sigmoid function\n",
    "        self.dinputs = dvalues * (1 - self.output) * self.output\n",
    "\n",
    "    # Calculate predictions for outputs\n",
    "    def predictions(self, outputs):\n",
    "        return (outputs > 0.5) * 1\n",
    "\n",
    "\n",
    "# Linear activation\n",
    "class Activation_Linear:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, training):\n",
    "        # Just remember values\n",
    "        self.inputs = inputs\n",
    "        self.output = inputs\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # derivative is 1, 1 * dvalues = dvalues - the chain rule\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "    # Calculate predictions for outputs\n",
    "    def predictions(self, outputs):\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# SGD optimizer\n",
    "class Optimizer_SGD:\n",
    "\n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If we use momentum\n",
    "        if self.momentum:\n",
    "\n",
    "            # If layer does not contain momentum arrays, create them\n",
    "            # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = \\\n",
    "                self.momentum * layer.weight_momentums - \\\n",
    "                self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            # Build bias updates\n",
    "            bias_updates = \\\n",
    "                self.momentum * layer.bias_momentums - \\\n",
    "                self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        # Vanilla SGD updates (as before momentum update)\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * \\\n",
    "                             layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * \\\n",
    "                           layer.dbiases\n",
    "\n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Adagrad optimizer\n",
    "class Optimizer_Adagrad:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * \\\n",
    "                         layer.dweights / \\\n",
    "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * \\\n",
    "                        layer.dbiases / \\\n",
    "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# RMSprop optimizer\n",
    "class Optimizer_RMSprop:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
    "                 rho=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + \\\n",
    "            (1 - self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + \\\n",
    "            (1 - self.rho) * layer.dbiases**2\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * \\\n",
    "                         layer.dweights / \\\n",
    "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * \\\n",
    "                        layer.dbiases / \\\n",
    "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Adam optimizer\n",
    "class Optimizer_Adam:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
    "                 beta_1=0.9, beta_2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update momentum  with current gradients\n",
    "        layer.weight_momentums = self.beta_1 * \\\n",
    "                                 layer.weight_momentums + \\\n",
    "                                 (1 - self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * \\\n",
    "                               layer.bias_momentums + \\\n",
    "                               (1 - self.beta_1) * layer.dbiases\n",
    "        # Get corrected momentum\n",
    "        # self.iteration is 0 at first pass\n",
    "        # and we need to start with 1 here\n",
    "        weight_momentums_corrected = layer.weight_momentums / \\\n",
    "            (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / \\\n",
    "            (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
    "            (1 - self.beta_2) * layer.dweights**2\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
    "            (1 - self.beta_2) * layer.dbiases**2\n",
    "        # Get corrected cache\n",
    "        weight_cache_corrected = layer.weight_cache / \\\n",
    "            (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        bias_cache_corrected = layer.bias_cache / \\\n",
    "            (1 - self.beta_2 ** (self.iterations + 1))\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * \\\n",
    "                         weight_momentums_corrected / \\\n",
    "                         (np.sqrt(weight_cache_corrected) +\n",
    "                             self.epsilon)\n",
    "\n",
    "        layer.biases += -self.current_learning_rate * \\\n",
    "                         bias_momentums_corrected / \\\n",
    "                         (np.sqrt(bias_cache_corrected) +\n",
    "                             self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Regularization loss calculation\n",
    "    def regularization_loss(self):\n",
    "\n",
    "        # 0 by default\n",
    "        regularization_loss = 0\n",
    "\n",
    "        # Calculate regularization loss\n",
    "        # iterate all trainable layers\n",
    "        for layer in self.trainable_layers:\n",
    "\n",
    "            # L1 regularization - weights\n",
    "            # calculate only when factor greater than 0\n",
    "            if layer.weight_regularizer_l1 > 0:\n",
    "                regularization_loss += layer.weight_regularizer_l1 * \\\n",
    "                                       np.sum(np.abs(layer.weights))\n",
    "\n",
    "            # L2 regularization - weights\n",
    "            if layer.weight_regularizer_l2 > 0:\n",
    "                regularization_loss += layer.weight_regularizer_l2 * \\\n",
    "                                       np.sum(layer.weights * \\\n",
    "                                              layer.weights)\n",
    "\n",
    "            # L1 regularization - biases\n",
    "            # calculate only when factor greater than 0\n",
    "            if layer.bias_regularizer_l1 > 0:\n",
    "                regularization_loss += layer.bias_regularizer_l1 * \\\n",
    "                                       np.sum(np.abs(layer.biases))\n",
    "\n",
    "            # L2 regularization - biases\n",
    "            if layer.bias_regularizer_l2 > 0:\n",
    "                regularization_loss += layer.bias_regularizer_l2 * \\\n",
    "                                       np.sum(layer.biases * \\\n",
    "                                              layer.biases)\n",
    "\n",
    "        return regularization_loss\n",
    "\n",
    "\n",
    "    # Set/remember trainable layers\n",
    "    def remember_trainable_layers(self, trainable_layers):\n",
    "        self.trainable_layers = trainable_layers\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y, *, include_regularization=False):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Add accumulated sum of losses and sample count\n",
    "        self.accumulated_sum += np.sum(sample_losses)\n",
    "        self.accumulated_count += len(sample_losses)\n",
    "\n",
    "        # If just data loss - return it\n",
    "        if not include_regularization:\n",
    "            return data_loss\n",
    "\n",
    "        # Return the data and regularization losses\n",
    "        return data_loss, self.regularization_loss()\n",
    "\n",
    "    # Calculates accumulated loss\n",
    "    def calculate_accumulated(self, *, include_regularization=False):\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = self.accumulated_sum / self.accumulated_count\n",
    "\n",
    "        # If just data loss - return it\n",
    "        if not include_regularization:\n",
    "            return data_loss\n",
    "\n",
    "        # Return the data and regularization losses\n",
    "        return data_loss, self.regularization_loss()\n",
    "\n",
    "    # Reset variables for accumulated loss\n",
    "    def new_pass(self):\n",
    "        self.accumulated_sum = 0\n",
    "        self.accumulated_count = 0\n",
    "\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Binary cross-entropy loss\n",
    "class Loss_BinaryCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Calculate sample-wise loss\n",
    "        sample_losses = -(y_true * np.log(y_pred_clipped) +\n",
    "                          (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        sample_losses = np.mean(sample_losses, axis=-1)\n",
    "\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -(y_true / clipped_dvalues -\n",
    "                         (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Mean Squared Error loss\n",
    "class Loss_MeanSquaredError(Loss):  # L2 loss\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Calculate loss\n",
    "        sample_losses = np.mean((y_true - y_pred)**2, axis=-1)\n",
    "\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = -2 * (y_true - dvalues) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Mean Absolute Error loss\n",
    "class Loss_MeanAbsoluteError(Loss):  # L1 loss\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Calculate loss\n",
    "        sample_losses = np.mean(np.abs(y_true - y_pred), axis=-1)\n",
    "\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = np.sign(y_true - dvalues) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Common accuracy class\n",
    "class Accuracy:\n",
    "\n",
    "    # Calculates an accuracy\n",
    "    # given predictions and ground truth values\n",
    "    def calculate(self, predictions, y):\n",
    "\n",
    "        # Get comparison results\n",
    "        comparisons = self.compare(predictions, y)\n",
    "\n",
    "        # Calculate an accuracy\n",
    "        accuracy = np.mean(comparisons)\n",
    "\n",
    "        # Add accumulated sum of matching values and sample count\n",
    "        self.accumulated_sum += np.sum(comparisons)\n",
    "        self.accumulated_count += len(comparisons)\n",
    "\n",
    "        # Return accuracy\n",
    "        return accuracy\n",
    "\n",
    "    # Calculates accumulated accuracy\n",
    "    def calculate_accumulated(self):\n",
    "\n",
    "        # Calculate an accuracy\n",
    "        accuracy = self.accumulated_sum / self.accumulated_count\n",
    "\n",
    "        # Return the data and regularization losses\n",
    "        return accuracy\n",
    "\n",
    "    # Reset variables for accumulated accuracy\n",
    "    def new_pass(self):\n",
    "        self.accumulated_sum = 0\n",
    "        self.accumulated_count = 0\n",
    "\n",
    "\n",
    "# Accuracy calculation for classification model\n",
    "class Accuracy_Categorical(Accuracy):\n",
    "\n",
    "    def __init__(self, *, binary=False):\n",
    "        # Binary mode?\n",
    "        self.binary = binary\n",
    "\n",
    "    # No initialization is needed\n",
    "    def init(self, y):\n",
    "        pass\n",
    "\n",
    "    # Compares predictions to the ground truth values\n",
    "    def compare(self, predictions, y):\n",
    "        if not self.binary and len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    "        return predictions == y\n",
    "\n",
    "\n",
    "# Accuracy calculation for regression model\n",
    "class Accuracy_Regression(Accuracy):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create precision property\n",
    "        self.precision = None\n",
    "\n",
    "    # Calculates precision value\n",
    "    # based on passed-in ground truth values\n",
    "    def init(self, y, reinit=False):\n",
    "        if self.precision is None or reinit:\n",
    "            self.precision = np.std(y) / 250\n",
    "\n",
    "    # Compares predictions to the ground truth values\n",
    "    def compare(self, predictions, y):\n",
    "        return np.absolute(predictions - y) < self.precision\n",
    "\n",
    "\n",
    "# Model class\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create a list of network objects\n",
    "        self.layers = []\n",
    "        # Softmax classifier's output object\n",
    "        self.softmax_classifier_output = None\n",
    "\n",
    "    # Add objects to the model\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "\n",
    "    # Set loss, optimizer and accuracy\n",
    "    def set(self, *, loss = None, optimizer = None, accuracy = None):\n",
    "        if loss is not None:\n",
    "            self.loss = loss\n",
    "        if optimizer is not None:\n",
    "            self.optimizer = optimizer\n",
    "        if accuracy is not None:\n",
    "            self.accuracy = accuracy\n",
    "\n",
    "    # Finalize the model\n",
    "    def finalize(self):\n",
    "\n",
    "        # Create and set the input layer\n",
    "        self.input_layer = Layer_Input()\n",
    "\n",
    "        # Count all the objects\n",
    "        layer_count = len(self.layers)\n",
    "\n",
    "        # Initialize a list containing trainable layers:\n",
    "        self.trainable_layers = []\n",
    "\n",
    "        # Iterate the objects\n",
    "        for i in range(layer_count):\n",
    "\n",
    "            # If it's the first layer,\n",
    "            # the previous layer object is the input layer\n",
    "            if i == 0:\n",
    "                self.layers[i].prev = self.input_layer\n",
    "                self.layers[i].next = self.layers[i+1]\n",
    "\n",
    "            # All layers except for the first and the last\n",
    "            elif i < layer_count - 1:\n",
    "                self.layers[i].prev = self.layers[i-1]\n",
    "                self.layers[i].next = self.layers[i+1]\n",
    "\n",
    "            # The last layer - the next object is the loss\n",
    "            # Also let's save aside the reference to the last object\n",
    "            # whose output is the model's output\n",
    "            else:\n",
    "                self.layers[i].prev = self.layers[i-1]\n",
    "                self.layers[i].next = self.loss\n",
    "                self.output_layer_activation = self.layers[i]\n",
    "\n",
    "            # If layer contains an attribute called \"weights\",\n",
    "            # it's a trainable layer -\n",
    "            # add it to the list of trainable layers\n",
    "            # We don't need to check for biases -\n",
    "            # checking for weights is enough\n",
    "            if hasattr(self.layers[i], 'weights'):\n",
    "                self.trainable_layers.append(self.layers[i])\n",
    "\n",
    "\n",
    "        # Update loss object with trainable layers\n",
    "        if self.loss is not None:\n",
    "            self.loss.remember_trainable_layers(\n",
    "                self.trainable_layers\n",
    "            )\n",
    "\n",
    "        # If output activation is Softmax and\n",
    "        # loss function is Categorical Cross-Entropy\n",
    "        # create an object of combined activation\n",
    "        # and loss function containing\n",
    "        # faster gradient calculation\n",
    "        if isinstance(self.layers[-1], Activation_Softmax) and \\\n",
    "           isinstance(self.loss, Loss_CategoricalCrossentropy):\n",
    "            # Create an object of combined activation\n",
    "            # and loss functions\n",
    "            self.softmax_classifier_output = \\\n",
    "                Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Train the model\n",
    "    def train(self, X, y, *, epochs=1, batch_size=None,\n",
    "              print_every=1, validation_data=None):\n",
    "\n",
    "        # Initialize accuracy object\n",
    "        self.accuracy.init(y)\n",
    "\n",
    "        # Default value if batch size is not being set\n",
    "        train_steps = 1\n",
    "\n",
    "        # If there is validation data passed,\n",
    "        # set default number of steps for validation as well\n",
    "        if validation_data is not None:\n",
    "            validation_steps = 1\n",
    "\n",
    "            # For better readability\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        # Calculate number of steps\n",
    "        if batch_size is not None:\n",
    "            train_steps = len(X) // batch_size\n",
    "            # Dividing rounds down. If there are some remaining\n",
    "            # data but not a full batch, this won't include it\n",
    "            # Add `1` to include this not full batch\n",
    "            if train_steps * batch_size < len(X):\n",
    "                train_steps += 1\n",
    "\n",
    "            if validation_data is not None:\n",
    "                validation_steps = len(X_val) // batch_size\n",
    "\n",
    "                # Dividing rounds down. If there are some remaining\n",
    "                # data but nor full batch, this won't include it\n",
    "                # Add `1` to include this not full batch\n",
    "                if validation_steps * batch_size < len(X_val):\n",
    "                    validation_steps += 1\n",
    "\n",
    "        # Main training loop\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            # Print epoch number\n",
    "            print(f'epoch: {epoch}')\n",
    "\n",
    "            # Reset accumulated values in loss and accuracy objects\n",
    "            self.loss.new_pass()\n",
    "            self.accuracy.new_pass()\n",
    "\n",
    "            # Iterate over steps\n",
    "            for step in range(train_steps):\n",
    "\n",
    "                # If batch size is not set -\n",
    "                # train using one step and full dataset\n",
    "                if batch_size is None:\n",
    "                    batch_X = X\n",
    "                    batch_y = y\n",
    "\n",
    "                # Otherwise slice a batch\n",
    "                else:\n",
    "                    batch_X = X[step*batch_size:(step+1)*batch_size]\n",
    "                    batch_y = y[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "                # Perform the forward pass\n",
    "                output = self.forward(batch_X, training=True)\n",
    "\n",
    "                # Calculate loss\n",
    "                data_loss, regularization_loss = \\\n",
    "                    self.loss.calculate(output, batch_y,\n",
    "                                        include_regularization=True)\n",
    "                loss = data_loss + regularization_loss\n",
    "\n",
    "                # Get predictions and calculate an accuracy\n",
    "                predictions = self.output_layer_activation.predictions(\n",
    "                                  output)\n",
    "                accuracy = self.accuracy.calculate(predictions,\n",
    "                                                   batch_y)\n",
    "\n",
    "                # Perform backward pass\n",
    "                self.backward(output, batch_y)\n",
    "\n",
    "\n",
    "                # Optimize (update parameters)\n",
    "                self.optimizer.pre_update_params()\n",
    "                for layer in self.trainable_layers:\n",
    "                    self.optimizer.update_params(layer)\n",
    "                self.optimizer.post_update_params()\n",
    "\n",
    "                # Print a summary\n",
    "                if not step % print_every or step == train_steps - 1:\n",
    "                    print(f'step: {step}, ' +\n",
    "                          f'acc: {accuracy:.3f}, ' +\n",
    "                          f'loss: {loss:.3f} (' +\n",
    "                          f'data_loss: {data_loss:.3f}, ' +\n",
    "                          f'reg_loss: {regularization_loss:.3f}), ' +\n",
    "                          f'lr: {self.optimizer.current_learning_rate}')\n",
    "\n",
    "            # Get and print epoch loss and accuracy\n",
    "            epoch_data_loss, epoch_regularization_loss = \\\n",
    "                self.loss.calculate_accumulated(\n",
    "                    include_regularization=True)\n",
    "            epoch_loss = epoch_data_loss + epoch_regularization_loss\n",
    "            epoch_accuracy = self.accuracy.calculate_accumulated()\n",
    "\n",
    "            print(f'training, ' +\n",
    "                  f'acc: {epoch_accuracy:.3f}, ' +\n",
    "                  f'loss: {epoch_loss:.3f} (' +\n",
    "                  f'data_loss: {epoch_data_loss:.3f}, ' +\n",
    "                  f'reg_loss: {epoch_regularization_loss:.3f}), ' +\n",
    "                  f'lr: {self.optimizer.current_learning_rate}')\n",
    "\n",
    "            # If there is the validation data\n",
    "            if validation_data is not None:\n",
    "\n",
    "                # evaluate the model\n",
    "                self.evaluate(*validation_data,\n",
    "                              batch_size = batch_size)\n",
    "                # * explodes the data into individual arguments\n",
    "\n",
    "    # Performs forward pass\n",
    "    def forward(self, X, training):\n",
    "\n",
    "        # Call forward method on the input layer\n",
    "        # this will set the output property that\n",
    "        # the first layer in \"prev\" object is expecting\n",
    "        self.input_layer.forward(X, training)\n",
    "\n",
    "        # Call forward method of every object in a chain\n",
    "        # Pass output of the previous object as a parameter\n",
    "        for layer in self.layers:\n",
    "            layer.forward(layer.prev.output, training)\n",
    "\n",
    "        # \"layer\" is now the last object from the list,\n",
    "        # return its output\n",
    "        return layer.output\n",
    "\n",
    "\n",
    "    # Performs backward pass\n",
    "    def backward(self, output, y):\n",
    "\n",
    "        # If softmax classifier\n",
    "        if self.softmax_classifier_output is not None:\n",
    "            # First call backward method\n",
    "            # on the combined activation/loss\n",
    "            # this will set dinputs property\n",
    "            self.softmax_classifier_output.backward(output, y)\n",
    "\n",
    "            # Since we'll not call backward method of the last layer\n",
    "            # which is Softmax activation\n",
    "            # as we used combined activation/loss\n",
    "            # object, let's set dinputs in this object\n",
    "            self.layers[-1].dinputs = \\\n",
    "                self.softmax_classifier_output.dinputs\n",
    "\n",
    "            # Call backward method going through\n",
    "            # all the objects but last\n",
    "            # in reversed order passing dinputs as a parameter\n",
    "            for layer in reversed(self.layers[:-1]):\n",
    "                layer.backward(layer.next.dinputs)\n",
    "\n",
    "            return\n",
    "\n",
    "        # First call backward method on the loss\n",
    "        # this will set dinputs property that the last\n",
    "        # layer will try to access shortly\n",
    "        self.loss.backward(output, y)\n",
    "\n",
    "        # Call backward method going through all the objects\n",
    "        # in reversed order passing dinputs as a parameter\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward(layer.next.dinputs)\n",
    "    \n",
    "    # evaluates the model using passed in dataset\n",
    "    def evaluate(self, X_val, y_val, *, batch_size = None):\n",
    "        \n",
    "        # default value if batch size is not being set\n",
    "        validation_steps = 1\n",
    "        \n",
    "        # calculate number of steps\n",
    "        if batch_size is not None:\n",
    "            validation_steps = len(X_val) // batch_size\n",
    "            # another batch from remainders\n",
    "            if validation_steps * batch_size < len(X_val):\n",
    "                validation_steps += 1\n",
    "\n",
    "        # Reset accumulated values in loss\n",
    "        # and accuracy objects\n",
    "        self.loss.new_pass()\n",
    "        self.accuracy.new_pass()\n",
    "\n",
    "        # Iterate over steps\n",
    "        for step in range(validation_steps):\n",
    "\n",
    "            # If batch size is not set -\n",
    "            # train using one step and full dataset\n",
    "            if batch_size is None:\n",
    "                batch_X = X_val\n",
    "                batch_y = y_val\n",
    "\n",
    "\n",
    "            # Otherwise slice a batch\n",
    "            else:\n",
    "                batch_X = X_val[\n",
    "                    step*batch_size:(step+1)*batch_size\n",
    "                ]\n",
    "                batch_y = y_val[\n",
    "                    step*batch_size:(step+1)*batch_size\n",
    "                ]\n",
    "\n",
    "            # Perform the forward pass\n",
    "            output = self.forward(batch_X, training=False)\n",
    "\n",
    "            # Calculate the loss\n",
    "            self.loss.calculate(output, batch_y)\n",
    "\n",
    "            # Get predictions and calculate an accuracy\n",
    "            predictions = self.output_layer_activation.predictions(\n",
    "                              output)\n",
    "            self.accuracy.calculate(predictions, batch_y)\n",
    "\n",
    "        # Get and print validation loss and accuracy\n",
    "        validation_loss = self.loss.calculate_accumulated()\n",
    "        validation_accuracy = self.accuracy.calculate_accumulated()\n",
    "\n",
    "        # Print a summary\n",
    "        print(f'validation, ' +\n",
    "              f'acc: {validation_accuracy:.3f}, ' +\n",
    "              f'loss: {validation_loss:.3f}')\n",
    "\n",
    "    # Retrieves and returns parameters of trainable layers\n",
    "    def get_parameters(self):\n",
    "        \n",
    "        # create a list for paremeters\n",
    "        parameters = []\n",
    "        \n",
    "        # iterate trainable layers and get their parameters\n",
    "        for layer in self.trainable_layers:\n",
    "            parameters.append(layer.get_parameters())\n",
    "            \n",
    "        # return a list\n",
    "        return parameters\n",
    "    \n",
    "    # Updates the model with new parameters\n",
    "    def set_parameters(self, parameters):\n",
    "        \n",
    "        # iterate over the parameters and layers\n",
    "        # and update each layers with each set of the parameters\n",
    "        for parameter_set, layer in zip(parameters, \n",
    "                                        self.trainable_layers):\n",
    "            layer.set_parameters(*parameter_set)\n",
    "            \n",
    "    # saves the parameters to a file\n",
    "    def save_parameters(self, path):\n",
    "        \n",
    "        # open a file in the binary-write mode\n",
    "        # and save parameters to it\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.get_parameters(), f)\n",
    "            \n",
    "    # loads the weights and updates a model instance with them\n",
    "    def load_paremeters(self, path):\n",
    "        \n",
    "        # open file in the binary-read mode,\n",
    "        # load weights and update trainabe layers\n",
    "        with open(path, 'rb') as f:\n",
    "            self.set_parameters(pickle.load(f))\n",
    "            \n",
    "    def save(self, path):\n",
    "        \n",
    "        # make a deepy copy of the current model instance\n",
    "        model = copy.deepcopy(self)\n",
    "        \n",
    "        # reset accumulated values in loss and accuracy objects\n",
    "        model.loss.new_pass()\n",
    "        model.accuracy.new_pass()\n",
    "        \n",
    "        # remove data from the input layer\n",
    "        # and gradients from the loss object\n",
    "        model.input_layer.__dict__.pop('output', None)\n",
    "        model.loss.__dict__.pop('dinputs', None)\n",
    "        \n",
    "        # for each layer remove inputs, outputs and gradient properties\n",
    "        for layer in model.layers:\n",
    "            for property in ['inputs', 'output', 'dinputs', \n",
    "                             'dweights', 'dbiases']:\n",
    "                layer.__dict__.pop(property, None)\n",
    "                \n",
    "        # open a file in the binary-write mode and save the model\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "            \n",
    "    # loads and returns a model\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        \n",
    "        # open file in the binary-read mode\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            \n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "    def predict(self, X, *, batch_size = None):\n",
    "        \n",
    "        # Default value if batch size is not being set\n",
    "        prediction_steps = 1\n",
    "        \n",
    "        # calculate number of steps\n",
    "        if batch_size is not None:\n",
    "            prediction_steps = len(X) // batch_size\n",
    "            if prediction_steps * batch_size < len(X):\n",
    "                prediction_steps += 1\n",
    "        \n",
    "        # model outputs\n",
    "        output = []\n",
    "        \n",
    "        # iterate over steps\n",
    "        for step in range(prediction_steps):\n",
    "            \n",
    "            # if batch size is not set\n",
    "            # train using one step and full dataset\n",
    "            if batch_size is None:\n",
    "                batch_X = X\n",
    "            \n",
    "            # otherwise slice a batch\n",
    "            else:\n",
    "                batch_X = X[step * batch_size: (step + 1) * batch_size]\n",
    "            \n",
    "            # perform the forward pass\n",
    "            batch_output = self.forward(batch_X, training = False)\n",
    "            \n",
    "            # Append batch prediction to the list of predictions\n",
    "            output.append(batch_output)\n",
    "        \n",
    "        # stack and return results\n",
    "        return np.vstack(output)\n",
    "\n",
    "# Loads a MNIST dataset\n",
    "def load_mnist_dataset(dataset, path):\n",
    "\n",
    "    # Scan all the directories and create a list of labels\n",
    "    labels = os.listdir(os.path.join(path, dataset))\n",
    "\n",
    "    # Create lists for samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "\n",
    "    # For each label folder\n",
    "    for label in labels:\n",
    "        # And for each image in given folder\n",
    "        for file in os.listdir(os.path.join(path, dataset, label)):\n",
    "            # Read the image\n",
    "            image = cv2.imread(\n",
    "                        os.path.join(path, dataset, label, file),\n",
    "                        cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            # And append it and a label to the lists\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "\n",
    "    # Convert the data to proper numpy arrays and return\n",
    "    return np.array(X), np.array(y).astype('uint8')\n",
    "\n",
    "\n",
    "# MNIST dataset (train + test)\n",
    "def create_data_mnist(path):\n",
    "\n",
    "    # Load both sets separately\n",
    "    X, y = load_mnist_dataset('train', path)\n",
    "    X_test, y_test = load_mnist_dataset('test', path)\n",
    "\n",
    "    # And return all the data\n",
    "    return X, y, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630d5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y, X_test, y_test = create_data_mnist('fashion_mnist_images')\n",
    "\n",
    "# Shuffle the training dataset\n",
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys]\n",
    "\n",
    "# Scale and reshape samples\n",
    "X = (X.reshape(X.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
    "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) -\n",
    "             127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac4472fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.133, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.001\n",
      "step: 128, acc: 0.805, loss: 0.625 (data_loss: 0.625, reg_loss: 0.000), lr: 0.0008865248226950354\n",
      "step: 256, acc: 0.875, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0007961783439490446\n",
      "step: 384, acc: 0.789, loss: 0.478 (data_loss: 0.478, reg_loss: 0.000), lr: 0.0007225433526011561\n",
      "step: 468, acc: 0.875, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.000681198910081744\n",
      "training, acc: 0.787, loss: 0.577 (data_loss: 0.577, reg_loss: 0.000), lr: 0.000681198910081744\n",
      "validation, acc: 0.833, loss: 0.463\n",
      "epoch: 2\n",
      "step: 0, acc: 0.836, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0006807351940095304\n",
      "step: 128, acc: 0.828, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0006261740763932373\n",
      "step: 256, acc: 0.891, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0005797101449275362\n",
      "step: 384, acc: 0.836, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0005396654074473827\n",
      "step: 468, acc: 0.917, loss: 0.223 (data_loss: 0.223, reg_loss: 0.000), lr: 0.0005162622612287042\n",
      "training, acc: 0.859, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.0005162622612287042\n",
      "validation, acc: 0.857, loss: 0.399\n",
      "epoch: 3\n",
      "step: 0, acc: 0.844, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0005159958720330237\n",
      "step: 128, acc: 0.812, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.00048402710551790907\n",
      "step: 256, acc: 0.906, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.00045578851412944393\n",
      "step: 384, acc: 0.852, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0004306632213608957\n",
      "step: 468, acc: 0.917, loss: 0.191 (data_loss: 0.191, reg_loss: 0.000), lr: 0.0004156275976724854\n",
      "training, acc: 0.873, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0004156275976724854\n",
      "validation, acc: 0.865, loss: 0.373\n",
      "epoch: 4\n",
      "step: 0, acc: 0.875, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0004154549231408392\n",
      "step: 128, acc: 0.812, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0003944773175542406\n",
      "step: 256, acc: 0.906, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.00037551633496057073\n",
      "step: 384, acc: 0.852, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.00035829451809387314\n",
      "step: 468, acc: 0.938, loss: 0.168 (data_loss: 0.168, reg_loss: 0.000), lr: 0.00034782608695652176\n",
      "training, acc: 0.883, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.00034782608695652176\n",
      "validation, acc: 0.869, loss: 0.360\n",
      "epoch: 5\n",
      "step: 0, acc: 0.883, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0003477051460361613\n",
      "step: 128, acc: 0.836, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.00033288948069241014\n",
      "step: 256, acc: 0.906, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.00031928480204342275\n",
      "step: 384, acc: 0.859, loss: 0.304 (data_loss: 0.304, reg_loss: 0.000), lr: 0.00030674846625766873\n",
      "step: 468, acc: 0.958, loss: 0.154 (data_loss: 0.154, reg_loss: 0.000), lr: 0.0002990430622009569\n",
      "training, acc: 0.890, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000), lr: 0.0002990430622009569\n",
      "validation, acc: 0.873, loss: 0.352\n",
      "epoch: 6\n",
      "step: 0, acc: 0.891, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.0002989536621823617\n",
      "step: 128, acc: 0.836, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0002879355024474518\n",
      "step: 256, acc: 0.898, loss: 0.272 (data_loss: 0.272, reg_loss: 0.000), lr: 0.00027770063871146905\n",
      "step: 384, acc: 0.883, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0002681684097613301\n",
      "step: 468, acc: 0.958, loss: 0.138 (data_loss: 0.138, reg_loss: 0.000), lr: 0.00026226068712300026\n",
      "training, acc: 0.895, loss: 0.284 (data_loss: 0.284, reg_loss: 0.000), lr: 0.00026226068712300026\n",
      "validation, acc: 0.876, loss: 0.346\n",
      "epoch: 7\n",
      "step: 0, acc: 0.891, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.00026219192448872575\n",
      "step: 128, acc: 0.844, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0002536783358701167\n",
      "step: 256, acc: 0.906, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0002457002457002457\n",
      "step: 384, acc: 0.875, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.00023820867079561695\n",
      "step: 468, acc: 0.958, loss: 0.125 (data_loss: 0.125, reg_loss: 0.000), lr: 0.00023353573096683791\n",
      "training, acc: 0.900, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000), lr: 0.00023353573096683791\n",
      "validation, acc: 0.878, loss: 0.339\n",
      "epoch: 8\n",
      "step: 0, acc: 0.891, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.00023348120476301658\n",
      "step: 128, acc: 0.852, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.00022670596236681027\n",
      "step: 256, acc: 0.906, loss: 0.262 (data_loss: 0.262, reg_loss: 0.000), lr: 0.00022031284423881914\n",
      "step: 384, acc: 0.891, loss: 0.269 (data_loss: 0.269, reg_loss: 0.000), lr: 0.0002142704092564817\n",
      "step: 468, acc: 0.958, loss: 0.118 (data_loss: 0.118, reg_loss: 0.000), lr: 0.00021048200378867611\n",
      "training, acc: 0.904, loss: 0.260 (data_loss: 0.260, reg_loss: 0.000), lr: 0.00021048200378867611\n",
      "validation, acc: 0.881, loss: 0.334\n",
      "epoch: 9\n",
      "step: 0, acc: 0.898, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0002104377104377104\n",
      "step: 128, acc: 0.852, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.00020491803278688525\n",
      "step: 256, acc: 0.898, loss: 0.254 (data_loss: 0.254, reg_loss: 0.000), lr: 0.00019968051118210864\n",
      "step: 384, acc: 0.891, loss: 0.262 (data_loss: 0.262, reg_loss: 0.000), lr: 0.00019470404984423675\n",
      "step: 468, acc: 0.958, loss: 0.109 (data_loss: 0.109, reg_loss: 0.000), lr: 0.00019157088122605365\n",
      "training, acc: 0.907, loss: 0.250 (data_loss: 0.250, reg_loss: 0.000), lr: 0.00019157088122605365\n",
      "validation, acc: 0.881, loss: 0.330\n",
      "epoch: 10\n",
      "step: 0, acc: 0.898, loss: 0.267 (data_loss: 0.267, reg_loss: 0.000), lr: 0.0001915341888527102\n",
      "step: 128, acc: 0.852, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.00018695083193120211\n",
      "step: 256, acc: 0.891, loss: 0.246 (data_loss: 0.246, reg_loss: 0.000), lr: 0.0001825817053131276\n",
      "step: 384, acc: 0.891, loss: 0.255 (data_loss: 0.255, reg_loss: 0.000), lr: 0.0001784121320249777\n",
      "step: 468, acc: 0.958, loss: 0.104 (data_loss: 0.104, reg_loss: 0.000), lr: 0.00017577781683951485\n",
      "training, acc: 0.911, loss: 0.241 (data_loss: 0.241, reg_loss: 0.000), lr: 0.00017577781683951485\n",
      "validation, acc: 0.883, loss: 0.328\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = Model()\n",
    "\n",
    "\n",
    "# Add layers\n",
    "model.add(Layer_Dense(X.shape[1], 256))\n",
    "model.add(Activation_ReLU())\n",
    "model.add(Layer_Dense(256, 256))\n",
    "model.add(Activation_ReLU())\n",
    "model.add(Layer_Dense(256, 10))\n",
    "model.add(Activation_Softmax())\n",
    "\n",
    "# Set loss, optimizer and accuracy objects\n",
    "model.set(\n",
    "    loss=Loss_CategoricalCrossentropy(),\n",
    "    optimizer=Optimizer_Adam(decay=1e-3),\n",
    "    accuracy=Accuracy_Categorical()\n",
    ")\n",
    "\n",
    "# Finalize the model\n",
    "model.finalize()\n",
    "\n",
    "# Train the model\n",
    "model.train(X, y, validation_data=(X_test, y_test),\n",
    "            epochs=10, batch_size=128, print_every=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d61c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.916, loss: 0.229\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f2eccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fashion_mnist.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "847cdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_parameters('fashion_mnist.parms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff75a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Model()\n",
    "\n",
    "\n",
    "# Add layers\n",
    "model.add(Layer_Dense(X.shape[1], 256))\n",
    "model.add(Activation_ReLU())\n",
    "model.add(Layer_Dense(256, 256))\n",
    "model.add(Activation_ReLU())\n",
    "model.add(Layer_Dense(256, 10))\n",
    "model.add(Activation_Softmax())\n",
    "\n",
    "# Set loss, optimizer and accuracy objects\n",
    "model.set(\n",
    "    loss=Loss_CategoricalCrossentropy(),\n",
    "    optimizer=Optimizer_Adam(decay=1e-3),\n",
    "    accuracy=Accuracy_Categorical()\n",
    ")\n",
    "\n",
    "# Finalize the model\n",
    "model.finalize()\n",
    "\n",
    "model.load_paremeters('fashion_mnist.parms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "124e60ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.883, loss: 0.328\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c90a53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.883, loss: 0.328\n"
     ]
    }
   ],
   "source": [
    "new_model = Model.load('fashion_mnist.model')\n",
    "\n",
    "new_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58551747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8927629e-01, 4.0330222e-05, 2.8416139e-04, 9.9103061e-05,\n",
       "        1.3026219e-06, 2.0467821e-08, 1.0295438e-02, 1.2020305e-11,\n",
       "        3.2778903e-06, 2.7353768e-09],\n",
       "       [9.9847060e-01, 9.5061829e-08, 3.7275316e-04, 1.3581677e-05,\n",
       "        6.4583623e-09, 7.0581991e-12, 1.1427870e-03, 2.1228693e-15,\n",
       "        7.7662413e-08, 5.7655020e-13],\n",
       "       [5.7897252e-01, 2.2307651e-03, 4.6755141e-03, 3.1128727e-02,\n",
       "        4.4407072e-03, 2.8368097e-05, 3.7023047e-01, 5.8474893e-07,\n",
       "        8.2921516e-03, 2.5226680e-07],\n",
       "       [9.8264611e-01, 2.5911083e-06, 8.3329499e-04, 3.2227708e-04,\n",
       "        1.7461456e-07, 8.7401331e-09, 1.6190205e-02, 1.3887506e-12,\n",
       "        5.4160842e-06, 7.9766048e-11],\n",
       "       [9.7441024e-01, 5.4466815e-05, 1.1522959e-03, 5.9088616e-04,\n",
       "        9.5426924e-07, 5.4688464e-08, 2.3692736e-02, 2.4998402e-12,\n",
       "        9.8337769e-05, 1.8606677e-11]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e921fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "confidences = model.predict(X_test[7000])\n",
    "predictions = model.output_layer_activation.predictions(confidences)\n",
    "\n",
    "print(predictions)\n",
    "print(y_test[7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f320f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_labels = {\n",
    "    0: 'T-shirt/Top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9531b432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_data = cv2.imread('dress.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad44715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_data = cv2.imread('dress.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(image_data, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8a1a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_data = cv2.resize(image_data, (28, 28))\n",
    "\n",
    "plt.imshow(image_data, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "184bc202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20392156, 1.7647059 , 1.3333334 , 1.3333334 ,\n",
       "        1.082353  , 0.03137255, 0.        , 0.01568627, 1.8588235 ,\n",
       "        1.8588235 , 1.8588235 , 2.        , 2.        , 1.0117648 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 2.        ,\n",
       "        1.1764706 , 1.3490196 , 1.3490196 , 1.0509804 , 1.6705883 ,\n",
       "        0.        , 0.8392157 , 1.5843138 , 1.137255  , 1.137255  ,\n",
       "        1.0509804 , 1.3960785 , 1.7803922 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.        , 1.4352942 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.772549  , 1.9529412 , 1.8352941 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.9215686 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0862745 , 2.        ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 2.        , 0.83137256,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.        , 0.972549  , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3254902 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.882353  , 0.05490196, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18039215, 2.        ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.7411765 , 1.7882353 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 0.47843134,\n",
       "        0.7215686 , 2.        , 0.9254902 , 1.3960785 , 1.3960785 ,\n",
       "        0.52549016, 1.7568628 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07843137, 1.2       , 1.9058824 , 2.        ,\n",
       "        2.        , 2.        , 2.        , 1.9058824 , 1.9058824 ,\n",
       "        1.7019608 , 1.4901961 , 1.1529412 , 0.9098039 , 2.        ,\n",
       "        2.        , 1.5529412 , 1.4745098 , 2.        , 2.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        2.        , 0.67450976, 0.76862746, 0.78431374, 0.78431374,\n",
       "        0.78431374, 0.7294117 , 2.        , 0.        , 1.3333334 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 2.        , 1.4431373 ,\n",
       "        0.95686275, 0.9882353 , 0.9882353 , 0.9019608 , 0.8392157 ,\n",
       "        2.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.        , 1.6       , 1.4431373 , 1.4745098 ,\n",
       "        2.        , 2.        , 2.        , 1.7568628 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 2.        ,\n",
       "        1.4039216 , 1.372549  , 1.372549  , 1.3490196 , 1.3960785 ,\n",
       "        1.3960785 , 2.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.0745099 , 1.4196079 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 2.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 2.        ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.2392157 , 1.5137255 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 2.        , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 2.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        2.        , 1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 ,\n",
       "        1.3960785 , 1.3960785 , 1.3960785 , 1.3960785 , 2.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 2.        , 2.        ,\n",
       "        2.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "        1.6078432 , 1.2784314 , 2.        , 0.7607843 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5568627 , 0.8784314 ,\n",
       "        0.6588235 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data = 1 - (image_data.reshape(1, -1).astype(np.float32) -\n",
    "                 127.5) / 127.5\n",
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc2a75bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shirt'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidences = model.predict(image_data)\n",
    "predictions = model.output_layer_activation.predictions(confidences)\n",
    "\n",
    "fashion_mnist_labels[predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26336ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Trouser'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'pants.jpg'\n",
    "\n",
    "image_data = cv2.imread(name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "image_data = cv2.imread(name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(image_data, cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "image_data = cv2.resize(image_data, (28, 28))\n",
    "\n",
    "plt.imshow(image_data, cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "image_data = 1 - (image_data.reshape(1, -1).astype(np.float32) -\n",
    "                 127.5) / 127.5\n",
    "\n",
    "confidences = model.predict(image_data)\n",
    "predictions = model.output_layer_activation.predictions(confidences)\n",
    "\n",
    "fashion_mnist_labels[predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502e256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
